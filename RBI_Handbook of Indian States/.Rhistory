library(rvest)
library(dplyr)
library(stringr)
library(tidyverse)
library(RCurl)
library(readxl)
library(data.table)
colnames(final)
read.csv(up_data_final, paste0(getwd(), "/all_state_final.csv"))
read.csv(paste0(getwd(), "/all_state_final.csv"))
colnames(read.csv(paste0(getwd(), "/all_state_final.csv")))
comp_text<- c()
for (i in dfs){
temp=readtext(paste0(path, "/IMF Reports/imf_article_4_",i,".docx"))
temp$doc_id=i
comp_text<-rbind(temp, comp_text)
}
df_udp <- udpipe(comp_text, "english")
df_udp$stem<- wordStem(df_udp$token, language = "porter")
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))
comp_text<- c()
for (i in dfs){
temp=readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
temp$doc_id=i
comp_text<-rbind(temp, comp_text)
}
df_udp <- udpipe(comp_text, "english")
df_udp$stem<- wordStem(df_udp$token, language = "porter")
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))
paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx")
dfs<- c(2010,2012,2014,2015,2016,2017,2018,2019)
dfs <- as.Date(as.character(dfs), format = "%Y")
dfs <- year(dfs)
for (i in dfs){
temp=readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
temp$doc_id=i
comp_text<-rbind(temp, comp_text)
}
library(tidyverse)
library(tidytext)
library(textdata)
library(udpipe)
library(ggraph)
library(igraph)
library(SnowballC)
library(tm)
library(gridExtra)
library(rvest)
library(xml2)
library(readtext)
library(docxtractr)
library(sentimentr)
comp_text<- c()
for (i in dfs){
temp=readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
temp$doc_id=i
comp_text<-rbind(temp, comp_text)
}
df_udp <- udpipe(comp_text, "english")
df_udp$stem<- wordStem(df_udp$token, language = "porter")
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))
readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx")
readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
setwd()<-"C:/Users/pranj/Documents/GitHub/final-project-pranjal/"
setwd()<-"C:/Users/pranj/Documents/GitHub/final-project-pranjal/"
setwd("C:/Users/pranj/Documents/GitHub/final-project-pranjal/")
path<-getwd()
comp_text<- c()
for (i in dfs){
temp=readtext(paste0(getwd(), "/IMF Reports/imf_article_4_",i,".docx"))
temp$doc_id=i
comp_text<-rbind(temp, comp_text)
}
df_udp <- udpipe(comp_text, "english")
df_udp$stem<- wordStem(df_udp$token, language = "porter")
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))
frequency<-df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()
frequency<-df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()%>%
desc(arrange(n))
arrange(desc((n))
frequency<-df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()%>%
arrange(desc(n))
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()%>%
arrange(desc(n))
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()%>%
arrange(-desc(n))
df_udp%>%
filter(!lemma %in% stop_words,
!upos  %in% c("PUNCT", "CCONJ","NUM","SYM")) %>%
#mutate_if(is.character, str_to_lower) %>%
document_term_frequencies(term = "token")%>%
arrange(desc(freq))%>%
filter(term!="the"|term!="of"|term!="a"|term!="in")%>%
group_by(doc_id, term)%>%
count()%>%
arrange(desc(-n))
